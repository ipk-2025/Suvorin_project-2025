# Suvorin_project-2025
Итоговый проект 
-----

# Сравнительный анализ стилометрических систем для диахронического анализа авторского стиля

Этот репозиторий содержит материалы исследования, посвященного диахроническому анализу идиостиля А.С. Суворина на материале его писем за 1904-1908 гг. Основной исследовательский вопрос: можно ли зафиксировать измеримые изменения в стиле автора с течением времени?

Проект представляет собой эволюцию трех различных систем, каждая из которых отражает определенный этап в развитии методов компьютерной лингвистики и демонстрирует путь от классических подходов к современным гибридным моделям. 

## Описание систем

### Система 1: Классическая стилометрия и метод Delta

Это отправная точка исследования, использующая канонические подходы стилометрии. 

  * **Реализация:** Jupyter Notebook.
  * **Цель:** Кластеризация текстов по годам с использованием стандартных стилометрических методик. 
  * **Методология:**
      * **Данные:** Оцифрованные письма А.С. Суворина за 1904-1908 гг.
      * **Предобработка:** Токенизация, лемматизация, удаление стоп-слов. 
      * **Признаки:** Вектор частотностей наиболее употребимых слов. 
      * **Анализ:** Ключевым методом является `Burrows' Delta` — мера, вычисляющая расстояние между векторами частотностей слов. На основе этих расстояний строится дендрограмма для визуализации стилистической близости текстов.
  * **Оценка:**
      * **Преимущества:** Высокая интерпретируемость и воспроизводимость, является "золотым стандартом" в классической атрибуции. 
      * **Недостатки:** Учитывает только лексику, чувствителен к теме и игнорирует порядок слов (подход "мешок слов"). 

### Система 2: Гибридный подход с Word2Vec, графами и ансамблевым МО

Эта система является шагом вперед, переходя от подсчета частот к семантическому анализу и машинному обучению. 

  * **Цель:** Построение полноценного классификатора на основе множества признаков (лексических, синтаксических, семантических, графовых). 
  * **Методология:**
      * **Семантика:** Обучение модели `Word2Vec` для получения векторных представлений слов. 
      * **Инжиниринг признаков:** Создание комплексного набора признаков, включая лексическое разнообразие, частотность частей речи, усредненные векторы текстов и графовые метрики семантической когерентности. 
      * **Машинное обучение:** Использование ансамблевых методов (`RandomForestClassifier`, `GradientBoostingClassifier`) и их объединение в `VotingClassifier` для повышения качества. 
      * **Валидация:** Применение стратифицированной кросс-валидации (`StratifiedKFold`) и статистических тестов для надежной оценки точности. 
  * **Оценка:**
      * **Преимущества:** Глубина анализа (учет семантики), мощность ансамблевых методов. 
      * **Недостатки:** Сложность ручного инжиниринга признаков, низкая интерпретируемость ("черный ящик"). 

### Система 3: Гибридная модель на основе BERT и градиентного бустинга (v11)

Это финальная и наиболее успешная система, достигшая **пиковой точности 87.0%**. Она сочетает современные трансформерные эмбеддинги и классическое машинное обучение.

  * **Ключевая идея:** Отказ от нестабильного дообучения (fine-tuning) нейросетей в пользу надежного извлечения признаков с помощью BERT и их классификации алгоритмом `LightGBM`. 
  * **Методология:**
      * **Постановка задачи:** Задача была упрощена до бинарной классификации: "ранний период" (1904-1905) против "позднего периода" (1906-1907), что позволило модели сфокусироваться на более выраженных изменениях. 
      * **Семантические признаки (BERT):** Использование предобученной модели `DeepPavlov/rubert-base-cased` в режиме экстрактора. Для получения вектора текста применяется стратегия `Mean Pooling` (усреднение эмбеддингов всех токенов). Это дает 768 признаков. 
      * **Стилометрические признаки:** Параллельно генерируется более 2500 признаков (лексические, морфологические, n-граммы символов и частей речи). 
      * **Отбор признаков:** С помощью `SelectKBest` (на основе ANOVA F-test) из стилометрического набора отбираются 200 наиболее информативных признаков.
      * **Объединение:** Признаки от BERT (768) и стилометрические (200) объединяются в итоговый вектор размерностью 968. 
      *  **Классификация:** Используется `LightGBM` с параметрами, подобранными для баланса сложности и регуляризации.
      * **Оценка:** Применяется ансамблирование: 3 полных запуска 5-блочной стратифицированной кросс-валидации с разным `random_state` для минимизации случайности. 
  * **Оценка:**
      *  **Преимущества:** Высочайшая точность, стабильность и надежность благодаря отказу от дообучения BERT, автоматизация извлечения семантических признаков. 
      * **Недостатки:** Сложность интерпретации логики `LightGBM` и высокие вычислительные требования для извлечения BERT-эмбеддингов. 

## Как воспроизвести результаты (v11)

1.  **Клонируйте репозиторий:**
    ```bash
    git clone [URL-вашего-репозитория]
    cd [название-папки]
    ```
2.  **Установите зависимости:**
    ```bash
    pip install -r requirements.txt
    ```
3.  **Подготовьте данные:**
    Убедитесь, что файл с данными (`suvorin_letters.csv` или аналогичный) находится в корневой директории проекта.
4.  **Запустите скрипт:**
    ```bash
    python hybrid_bert_lgbm_classifier.py
    ```

## Источники

> [1] Burrows, J. F. (2002). 'Delta': a measure of stylistic difference and a guide to likely authorship. *Literary and Linguistic Computing, 17(3), 267-287*.
>
> [2] Mikolov, T., et al. (2013). Efficient estimation of word representations in vector space. *arXiv preprint arXiv:1301.3781*. 
>
> [3] Tripto N. I., Ali M. E. (2023). The Word2vec graph model for author attribution and genre detection in literary analysis. *arXiv preprint arXiv: 2310.16972*. 
>
> [4] Ke, G., et al. (2017). Lightgbm: A highly efficient gradient boosting decision tree. *Advances in neural information processing systems, 30*.
>
> [5] Kuratov, Y., et al. (2019). Adaptation of deep bidirectional transformers for Russian language. *arXiv preprint arXiv: 1905.07213*. 
